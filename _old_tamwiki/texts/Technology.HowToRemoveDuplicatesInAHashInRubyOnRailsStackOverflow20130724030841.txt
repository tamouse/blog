(:nolinkwikiwords:)
!!! [[http://stackoverflow.com:80/questions/5208344/how-to-remove-duplicates-in-a-hash-in-ruby-on-rails | How to remove duplicates in a hash in Ruby on Rails?]]

I have a hash like so:

(:source lang=ruby linenum tabwidth=2  :)
[
  {
    :lname => "Brown",
    :email => "james@intuit.com",
    :fname => "James"
  },
  {
    :lname => nil,
    :email => "brad@intuit.com",
    :fname => nil
  },
  {
    :lname => "Smith",
    :email => "brad@intuit.com",
    :fname => "Brad"
  },
  {
    :lname => nil,
    :email => "brad@intuit.com",
    :fname => nil
  },
  {
    :lname => "Smith",
    :email => "brad@intuit.com",
    :fname => "Brad"
  },
  {
    :lname => nil,
    :email => "brad@intuit.com",
    :fname => nil
  }
]
(:sourceend:)


What I would like to learn how to do is how to remove a record if it
is duplicate. Meaning, see how there are several "brad@intuit.com" how
can I remove the duplicate records, meaning remove all the others that
have an email of "brad@intuit.com".... Making email the key not the
other fields?



I know this is an old thread, but Rails has a method on 'Enumerable' called 'index_by' which can be handy in this case:



Now you can get the unique rows as follows:

(:source lang=ruby    :)
list.index_by {|r| r[:email]}.values
(:sourceend:)

To merge the rows with the same email id.


(:source lang=ruby    :)
list.group_by{|r| r[:email]}.map do |k, v| v.inject({}) {|r, h| r.merge(h){ |key, o, n| o || n } } end
(:sourceend:)

Custom but efficient method:

(:source lang=ruby    :)
list.inject({}) do |r, h| (r[h[:email]] ||= {}).merge!(h){ |key, old, new| old || new }  r end.values
(:sourceend:)

answered Mar 15 '11 at 18:39 [[http://stackoverflow.com:80/users/163203/harish-shetty | Harish Shetty]]



In Ruby 1.9.2, @@Array#uniq@@ will accept a block parameter which it
will use when comparing your objects:

(:source lang=ruby    :)
arrays.uniq { |h| h[:email] }
(:sourceend:)
  
[[http://stackoverflow.com:80/users/190985/dan-cheail | Dan Cheail]]

Ok, this (delete duplicates) is what you asked for:

(:source lang=ruby    :)
a.sort_by { |e| e[:email] }.inject([]) { |m,e| m.last.nil? ? [e] : m.last[:email] == e[:email] ? m : m &lt;&lt; e }
(:sourceend:)

But I think this (merge values) is what you want:

(:source lang=ruby    :)
a.sort_by { |e| e[:email] }.inject([]) { |m,e| m.last.nil? ? [e] : m.last[:email] == e[:email] ? (m.last.merge!(e) { |k,o,n| o  n }; m) : m &lt;&lt; e }
(:sourceend:)

Perhaps I'm stretching the one-liner idea a bit unreasonably, so with
different formatting and a test case: 

(:source lang=ruby  tabwidth=2 header="mergedups" :)
require 'pp'

a = [{:fname=>"James", :lname=>"Brown", :email=>"james@intuit.com"},
     {:fname=>nil,     :lname=>nil,     :email=>"brad@intuit.com"},
     {:fname=>"Brad",  :lname=>"Smith", :email=>"brad@intuit.com"},
     {:fname=>nil,     :lname=>nil,     :email=>"brad@intuit.com"},
     {:fname=>"Brad",  :lname=>"Smith", :email=>"brad@intuit.com"},
     {:fname=>"Brad",  :lname=>"Smith", :email=>"brad@intuit.com"}]

pp(
  a.sort_by { |e| e[:email] }.inject([]) do |m,e|
    m.last.nil? ? [e] :
      m.last[:email] == e[:email] ? (m.last.merge!(e) { |k,o,n| o || n }; m) :
        m << e
  end
)
(:sourceend:)

(:source lang=ruby   header="output" :)
[{:email=>"brad@intuit.com", :fname=>"Brad", :lname=>"Smith"},
 {:email=>"james@intuit.com", :fname=>"James", :lname=>"Brown"}]
(:sourceend:)


  
answered Mar 6 '11 at 3:26 [[http://stackoverflow.com:80/users/140740/digitalross | DigitalRoss]]

(:linkwikiwords:)

>>comment<<
Summary: a few ways to removing records with duplicate values residing in a hash, or merging records with duplicate values
Tags: saved page, ruby, hash, duplicate values
(:tags-hide saved page, ruby, hash, duplicate values:)
(:title How to remove duplicates in a hash in Ruby on Rails? - Stack Overflow:)
Source: http://stackoverflow.com/questions/5208344/how-to-remove-duplicates-in-a-hash-in-ruby-on-rails
Parent: (Technology.)Ruby
includeme: [[Technology.Ruby]]
Categories:[[!Articles]], [[!HowTos]]
>><<

Page saved at: Wed, 24 Jul 2013 03:08:41 -0500


